{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0152f35d",
   "metadata": {},
   "source": [
    "# Google Gemma 300m & Reranking\n",
    "Before moving to a reranker, I will test google gemma model, everything stays the same, just changing up the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf7937ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed8defd8484c4b9da841d4b997586d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91456f9aa10046d0a1c7b1773ad798d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd231170620f467dbdff2d6fa2e24af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a92a6c98b745f3afcf8f2382ff9a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6744f41ba6cc40c597a6df3c545d8de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import load_processed_data\n",
    "docs_for_splitter, questions_ground_truth = load_processed_data(\"../data/processed/squad_processed.pkl\")\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from transformers import AutoTokenizer\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/embeddinggemma-300m\")\n",
    "splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(tokenizer,chunk_size=512, chunk_overlap=75)\n",
    "splits = splitter.split_documents(docs_for_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8de7f196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81725035cea48c3a7b2e79b39d85910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/573 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b69759c760d84e238cd471558c93de33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/997 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e66162ca2cf409ab2e3601cafb1992c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/18.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65cdb5a68693490ba844c2b80dc89d35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/58.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3639cd26394b409c8b90eac533f47b99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/312 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026c70ecc8ce4fd69c09492c1f15a1d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/134 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf1362d343343bb9550cadb9ed745ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2_Dense/model.safetensors:   0%|          | 0.00/9.44M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df20d80d835424ca39b0dbc2110e090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/134 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b21f1548ab4c0e91ade22d9889c04f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3_Dense/model.safetensors:   0%|          | 0.00/9.44M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing index found. Generating embeddings...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "persist_directory = \"./chroma/04_google_gemma\"\n",
    "embed = HuggingFaceEmbeddings(model_name=\"google/embeddinggemma-300m\",\n",
    "                              encode_kwargs={'normalize_embeddings': True})\n",
    "if os.path.exists(persist_directory):\n",
    "    print(\"Loading existing embeddings...\")\n",
    "    vectorstore = Chroma(\n",
    "        persist_directory=persist_directory, \n",
    "        embedding_function=embed\n",
    "    )\n",
    "else:\n",
    "    print(\"No existing index found. Generating embeddings...\")\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=splits,\n",
    "        embedding=embed,\n",
    "        persist_directory=persist_directory,\n",
    "        collection_metadata={\"hnsw:space\": \"cosine\"}\n",
    "    )\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "123bd749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation on 2265 questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2265/2265 [02:56<00:00, 12.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Results ---\n",
      "MRR: 0.8527\n",
      "Hit Rate@1: 78.15%\n",
      "Hit Rate@3: 91.39%\n",
      "Hit Rate@5: 94.66%\n",
      "Hit Rate@7: 95.85%\n",
      "Hit Rate@10: 96.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import evaluate_retrieval\n",
    "\n",
    "results = evaluate_retrieval(questions_ground_truth,retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72222c8",
   "metadata": {},
   "source": [
    "We see great improvement with gemma with significantly shorter time needed to run both embedding and evaluation.<br>\n",
    "One more thing I will test is reranking. As we see the difference between hit rate@1 and hit rate@10 is about 18%, meaning if we can retrieve 10 paragraphs and rerank them succesfully, we can greatly increase top 1 metric.<br>\n",
    "I will use cross-encoder for MS Macro as he is quite light with only about 23 million parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a83debf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d01225bc0c34b9d9e29bb176ca42ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31545ebe52804f1aa8bae7d6f262cd03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690d8f44523c41d68283e0695e450d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e29e2be791744cfb0a257919275e199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d732a14b784927bfb28eb1df7ce5fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c50c88fd084b12b219f605d7a83ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7003fb7ece14e80a10c4020d65b9022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_classic.retrievers import ContextualCompressionRetriever\n",
    "from langchain_classic.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "\n",
    "model = HuggingFaceCrossEncoder(model_name=\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "\n",
    "compressor = CrossEncoderReranker(model=model, top_n=10)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, \n",
    "    base_retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90805395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation on 2265 questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2265/2265 [12:23<00:00,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Results ---\n",
      "MRR: 0.9226\n",
      "Hit Rate@1: 89.05%\n",
      "Hit Rate@3: 95.32%\n",
      "Hit Rate@5: 96.42%\n",
      "Hit Rate@7: 96.64%\n",
      "Hit Rate@10: 96.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# compression_retriever.invoke(questions_ground_truth[53]['question'])\n",
    "results_reranker = evaluate_retrieval(questions_ground_truth,compression_retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a574b3d5",
   "metadata": {},
   "source": [
    "Great improvemnt while time needed to run the evaluation is higher then with mixedbread's model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
