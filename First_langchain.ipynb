{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "682f0ffe",
   "metadata": {},
   "source": [
    "Loading selected 16 articles into dict of 16 strings to later turn them into documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d4d0325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "396c3af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "wanted = {}\n",
    "with open('./data/stanford-question-answering-dataset/dev-v1.1.json', 'r', encoding='utf-8') as f:\n",
    "    squad_data = json.load(f)\n",
    "all = squad_data['data']\n",
    "for i, article in enumerate(all):\n",
    "    if i==4 or i==19 :\n",
    "        wanted[article['title']] = article['paragraphs']\n",
    "with open('./data/stanford-question-answering-dataset/train-v1.1.json', 'r', encoding='utf-8') as f:\n",
    "    squad_data = json.load(f)\n",
    "all = squad_data['data']\n",
    "for i, article in enumerate(all):\n",
    "    if i in {30, 62, 104, 124, 149, 157, 177, 229, 293, 295, 330, 333, 389, 393} :\n",
    "        wanted[article['title']] = article['paragraphs']\n",
    "\n",
    "article_dict = {}\n",
    "context_dict = defaultdict(str)\n",
    "rows = []\n",
    "article_id=0\n",
    "context_id=0\n",
    "for title, contexts in wanted.items():\n",
    "    article_dict[article_id] = title\n",
    "    for i, element in enumerate(contexts):\n",
    "        # for getting paragraphs alone\n",
    "        # context_dict[context_id]=element.get('context')\n",
    "        # for getting whole article text\n",
    "        context_dict[article_id]+=element.get('context')\n",
    "        qas = element.get('qas', [])\n",
    "        for qa in qas:\n",
    "            row = {\n",
    "                'article_id': article_id,\n",
    "                'context_id': context_id,\n",
    "                'question_id': qa.get('id'),\n",
    "                'question': qa.get('question'),\n",
    "                'answers(list of dict)': qa.get('answers') # leave this for later i guess\n",
    "            }\n",
    "            rows.append(row)\n",
    "        context_id+=1\n",
    "    article_id+=1\n",
    "\n",
    "result_df = pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c9613e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "textovi = dict(context_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "093bf17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain_text_splitters as lts\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e1f2c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = lts.RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "docs = splitter.create_documents(textovi.values())\n",
    "splits = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54e69fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb8f9a99fc44201a1e74a71bf475f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a5caef08617433b9da0292f41a7209f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/266 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3506ed265acf42c4b93c648eecd6acb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42103dcc9dd4483a80e4a1bff9659db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6677123cac9042ae9cb6db15acefcbb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/677 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1499a56d9654e6eb246c015c6d0fe41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/670M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7812a6f65e42d1b559e63a0936ca75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/297 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embed = HuggingFaceEmbeddings(model_name=\"mixedbread-ai/mxbai-embed-large-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f79e3998",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=splits,embedding=embed)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e760d93",
   "metadata": {},
   "source": [
    "Kod iznad se prvi put izvrsavao skoro 7 minuta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2428307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='Computational complexity theory is a branch of the theory of computation in theoretical computer science that focuses on classifying computational problems according to their inherent difficulty, and relating those classes to each other. A computational problem is understood to be a task that is in principle amenable to being solved by a computer, which is equivalent to stating that the problem may be solved by mechanical application of mathematical steps, such as an algorithm.A problem is regarded as inherently difficult if its solution requires significant resources, whatever the algorithm used. The theory formalizes this intuition, by introducing mathematical models of computation to study these problems and quantifying the amount of resources needed to solve them, such as time and storage. Other complexity measures are also used, such as the amount of communication (used in communication complexity), the number of gates in a circuit (used in circuit complexity) and the number of'),\n",
       " Document(metadata={}, page_content='Other complexity measures are also used, such as the amount of communication (used in communication complexity), the number of gates in a circuit (used in circuit complexity) and the number of processors (used in parallel computing). One of the roles of computational complexity theory is to determine the practical limits on what computers can and cannot do.Closely related fields in theoretical computer science are analysis of algorithms and computability theory. A key distinction between analysis of algorithms and computational complexity theory is that the former is devoted to analyzing the amount of resources needed by a particular algorithm to solve a problem, whereas the latter asks a more general question about all possible algorithms that could be used to solve the same problem. More precisely, it tries to classify problems that can or cannot be solved with appropriately restricted resources. In turn, imposing restrictions on the available resources is what distinguishes'),\n",
       " Document(metadata={}, page_content='km. For this reason, complexity theory addresses computational problems and not particular problem instances.When considering computational problems, a problem instance is a string over an alphabet. Usually, the alphabet is taken to be the binary alphabet (i.e., the set {0,1}), and thus the strings are bitstrings. As in a real-world computer, mathematical objects other than bitstrings must be suitably encoded. For example, integers can be represented in binary notation, and graphs can be encoded directly via their adjacency matrices, or by encoding their adjacency lists in binary.Decision problems are one of the central objects of study in computational complexity theory. A decision problem is a special type of computational problem whose answer is either yes or no, or alternately either 1 or 0. A decision problem can be viewed as a formal language, where the members of the language are instances whose output is yes, and the non-members are those instances whose output is no. The'),\n",
       " Document(metadata={}, page_content='Trakhtenbrot (1956), a pioneer in the field from the USSR, studied another specific complexity measure. As he remembers:Even though some proofs of complexity-theoretic theorems regularly assume some concrete choice of input encoding, one tries to keep the discussion abstract enough to be independent of the choice of encoding. This can be achieved by ensuring that different representations can be transformed into each other efficiently.In 1967, Manuel Blum developed an axiomatic complexity theory based on his axioms and proved an important result, the so-called, speed-up theorem. The field really began to flourish in 1971 when the US researcher Stephen Cook and, working independently, Leonid Levin in the USSR, proved that there exist practically relevant problems that are NP-complete. In 1972, Richard Karp took this idea a leap forward with his landmark paper, \"Reducibility Among Combinatorial Problems\", in which he showed that 21 diverse combinatorial and graph theoretical problems,')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "givendocs = retriever.invoke(\"What branch of theoretical computer science de\")\n",
    "givendocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b57d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={}, page_content='the original 128K Mac, was an all-in-one computer. Its translucent plastic case, originally Bondi blue and later various additional colors, is considered an industrial design landmark of the late 1990s. The iMac did away with most of Apple\\'s standard (and usually proprietary) connections, such as SCSI and ADB, in favor of two USB ports. It replaced a floppy disk drive with a CD-ROM drive for installing software, but was incapable of writing to CDs or other media without external third-party hardware. The iMac proved to be phenomenally successful, with 800,000 units sold in 139 days. It made the company an annual profit of US$309 million, Apple\\'s first profitable year since Michael Spindler took over as CEO in 1995. This aesthetic was applied to the Power Macintosh and later the iBook, Apple\\'s first consumer-level laptop computer, filling the missing quadrant of Apple\\'s \"four-square product matrix\" (desktop and portable products for both consumers and professionals). More than 140,000'), Document(metadata={}, page_content='John Sculley, Jobs resigned from Apple in 1985. He went on to found NeXT, another computer company targeting the education market, and did not return until 1997, when Apple acquired NeXT.Jobs stated during the Macintosh\\'s introduction \"we expect Macintosh to become the third industry standard\", after the Apple II and IBM PC. Although outselling every other computer, it did not meet expectations during the first year, especially among business customers. Only about ten applications including MacWrite and MacPaint were widely available, although many non-Apple software developers participated in the introduction and Apple promised that 79 companies including Lotus, Digital Research, and Ashton-Tate were creating products for the new computer. After one year, it had less than one quarter of the software selection available compared to the IBM PC—including only one word processor, two databases, and one spreadsheet—although Apple had sold 280,000 Macintoshes compared to IBM\\'s first year'), Document(metadata={}, page_content='7 was the first Macintosh operating system to support 32-bit addressing. The following year, the Macintosh IIfx, starting at US$9,900, was unveiled. Apart from its fast 40 MHz 68030 processor, it had significant internal architectural improvements, including faster memory and two Apple II CPUs (6502s) dedicated to I/O processing.As for Mac OS, System 7 was a 32-bit rewrite from Pascal to C++ that introduced virtual memory and improved the handling of color graphics, as well as memory addressing, networking, and co-operative multitasking. Also during this time, the Macintosh began to shed the \"Snow White\" design language, along with the expensive consulting fees they were paying to Frogdesign. Apple instead brought the design work in-house by establishing the Apple Industrial Design Group, becoming responsible for crafting a new look for all Apple products.When Steve Jobs returned to Apple in 1997 following the company\\'s purchase of NeXT, he ordered that the OS that had been previewed'), Document(metadata={}, page_content=\"computer and helped to expand the emerging desktop publishing market.Raskin was authorized to start hiring for the project in September 1979, and he immediately asked his long-time colleague, Brian Howard, to join him. His initial team would eventually consist of himself, Howard, Joanna Hoffman, Burrell Smith, and Bud Tribble. The rest of the original Mac team would include Bill Atkinson, Bob Belleville, Steve Capps, George Crow, Donn Denman, Chris Espinosa, Andy Hertzfeld, Bruce Horn, Susan Kare, Larry Kenyon, and Caroline Rose with Steve Jobs leading the project.From 2001 to 2008, Mac sales increased continuously on an annual basis. Apple reported worldwide sales of 3.36 million Macs during the 2009 holiday season. As of Mid-2011, the Macintosh continues to enjoy rapid market share increase in the US, growing from 7.3% of all computer shipments in 2010 to 9.3% in 2011. According to IDC's quarterly PC tracker, globally, in 3rd quarter of 2014, Apple's PC market share increased 5.7\")]\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
